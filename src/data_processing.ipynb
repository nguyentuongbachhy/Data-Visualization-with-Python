{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<div style=\"\n",
            "    background-color: #E3F2FD; \n",
            "    padding: 20px; \n",
            "    text-align: center;\"\n",
            "    >\n",
            "    <h1 style=\"color: darkblue; font-family: Poppins, sans-serif; margin-bottom: 5px; font-weight: bold;\">\n",
            "        Tiền xử lý dữ liệu về diễn biến dịch Covid-19\n",
            "    </h1>\n",
            "    <h3 style=\"color:darkblue; font-family: Poppins, sans-serif; margin-top: 0;\">\n",
            "        Nhóm 9\n",
            "    </h3>\n",
            "<hr style=\"border: 2x solid darkblue;\">\n",
            "</div>\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Nhập các thư viện**"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "import os\n",
            "import re\n",
            "\n",
            "RAW_DATA_PATH = r\"../data/raw\"\n",
            "PROCESSED_DATA_PATH = r\"../data/processed\""
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Xử lý các file time series từ cumulative sang daily\n",
            "#### Mục tiêu:\n",
            "- Nhóm các dòng thuộc cùng 1 quốc gia lại với nhau\n",
            "- Xử lý dữ liệu từ thống kê tích lũy (cumulative) sang thống kê hằng ngày (daily) để có cái nhìn tổng quan hơn về số ca nhiễm, tử vong, hồi phục mới sau mỗi ngày"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Mở các file .csv liên quan đến time series và xuất ra dataframe**"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "global_time_series_files = [\n",
            "    'time_series_covid_19_confirmed.csv',\n",
            "    'time_series_covid_19_deaths.csv',\n",
            "    'time_series_covid_19_recovered.csv'\n",
            "]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "global_time_series_data = {}\n",
            "for file in global_time_series_files:\n",
            "    df = pd.read_csv(os.path.join(RAW_DATA_PATH, file))\n",
            "    key = file.replace(\"time_series_covid_19_\", \"\").replace(\".csv\", \"\")\n",
            "    global_time_series_data[key] = df\n",
            "\n",
            "    print(f\"{key}: {df.shape}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "confirmed_df = global_time_series_data.get(\"confirmed\")\n",
            "deaths_df = global_time_series_data.get(\"deaths\")\n",
            "recovered_df = global_time_series_data.get(\"recovered\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Theo file data_collection, có vài dòng chứa NaN, ta kiểm tra thử nội dung trong dòng đó như thế nào"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "columns_to_exclude = ['Province/State']  # Thay bằng các cột của bạn\n",
            "\n",
            "df_to_check = confirmed_df.drop(columns=columns_to_exclude)\n",
            "\n",
            "# Tìm các dòng có NaN trong các cột còn lại\n",
            "rows_with_nan = confirmed_df[df_to_check.isna().any(axis=1)]\n",
            "rows_with_nan"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Giá trị NaN là do tọa độ ở các điểm không xác định, điều này không quan trọng vì ta sẽ nhóm các dòng từ cùng một quốc gia lại với nhau nên sẽ có tọa độ lấy từ điểm hợp lệ đầu tiên trong mỗi quốc gia"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Viết hàm xử lý bộ dữ liệu.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def process_covid_data(df):\n",
            "    \"\"\"\n",
            "    Hàm xử lý chung cho cả 3 loại dữ liệu (confirmed, deaths, recovered)\n",
            "    Chuyển từ cumulative sang daily cases và giữ lại tọa độ\n",
            "    \"\"\"\n",
            "    # Gom nhóm theo quốc gia và tính tổng\n",
            "    processed_df = df.groupby('Country/Region').agg({\n",
            "    'Lat': 'first', #Lấy tọa độ từ giá trị đầu tiên trong mỗi nhóm quốc giâ\n",
            "    'Long': 'first',\n",
            "    **{col: 'sum' for col in df.columns if col not in ['Country/Region', 'Province/State', 'Lat', 'Long']}\n",
            "    })\n",
            "    processed_df.reset_index(inplace=True)\n",
            "\n",
            "    # Tách tọa độ và dữ liệu \n",
            "    location = processed_df[['Country/Region', 'Lat', 'Long']]\n",
            "    cumulative_cases = processed_df.drop(columns=['Country/Region', 'Lat', 'Long'])\n",
            "    \n",
            "    # Chuyển sang daily cases\n",
            "    daily_cases = cumulative_cases.copy()\n",
            "    daily_cases.iloc[:, 1:] = daily_cases.iloc[:, 1:].values - daily_cases.iloc[:, 0:-1].values\n",
            "    \n",
            "    # Kết hợp lại với tọa độ\n",
            "    result = pd.concat([location, daily_cases], axis=1)\n",
            "    \n",
            "    return result"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Xử lý chung cho cả 3 file dựa vào hàm xử lý"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Dictionary để lưu kết quả\n",
            "daily_data = {}\n",
            "\n",
            "# Xử lý từng file\n",
            "for key in global_time_series_data.keys():\n",
            "    df = global_time_series_data.get(key)\n",
            "    \n",
            "    # Tạo key cho dictionary (confirmed, deaths, recovered)\n",
            "    # Xử lý dữ liệu\n",
            "    daily_df = process_covid_data(df)\n",
            "    \n",
            "    # Lưu vào dictionary\n",
            "    daily_data[key] = daily_df\n",
            "    \n",
            "    print(f\"Đã xử lý xong {key}: {daily_df.shape}\")\n",
            "\n",
            "# Truy cập các DataFrame đã xử lý\n",
            "daily_confirmed = daily_data.get(\"confirmed\")\n",
            "daily_deaths = daily_data.get(\"deaths\")\n",
            "daily_recovered = daily_data.get(\"recovered\")\n",
            "\n",
            "# Kiểm tra kết quả\n",
            "print(\"\\nKích thước các DataFrame đã xử lý:\")\n",
            "print(f\"Daily confirmed cases: {daily_confirmed.shape}\")\n",
            "print(f\"Daily deaths: {daily_deaths.shape}\")\n",
            "print(f\"Daily recovered: {daily_recovered.shape}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Kiểm tra lại dữ liệu sau khi xử lý có giá trị âm trong các cases hay không"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Lấy daily_confirmed_dropped làm ví dụ\n",
            "# Tìm tất cả các ô có giá trị âm trong các cột số\n",
            "daily_confirmed_dropped = daily_confirmed.drop(columns=['Lat', 'Long'])\n",
            "negative_values = daily_confirmed_dropped.select_dtypes(include=['number'])[daily_confirmed_dropped.select_dtypes(include=['number']) < 0]\n",
            "\n",
            "# Tạo danh sách để lưu kết quả\n",
            "negative_list = []\n",
            "\n",
            "# Duyệt qua các cột có giá trị âm\n",
            "for col in negative_values.columns:\n",
            "    # Lấy các hàng có giá trị âm trong cột này\n",
            "    neg_rows = negative_values[col].dropna()\n",
            "    \n",
            "    # Thêm vào danh sách kết quả\n",
            "    for idx, value in neg_rows.items():\n",
            "        country = daily_confirmed_dropped.loc[idx, 'Country/Region']  # Hoặc 'Country' tùy tên cột của bạn\n",
            "        negative_list.append({\n",
            "            'Country': country,\n",
            "            'Date': col.replace('Daily_', '') if col.startswith('Daily_') else col,\n",
            "            'Negative_Value': value\n",
            "        })\n",
            "\n",
            "# Tạo DataFrame từ danh sách\n",
            "result = pd.DataFrame(negative_list)\n",
            "\n",
            "result"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "**Nguyên nhân**: Có thể do bộ phận thống kê loại bỏ các ca nhiễm dương tính giả, hoặc tiêu chuẩn đánh giá dương tính thay đổi trong quá trình thống kê. \\\n",
            "**Hướng giải quyết**: Chuyển các giá trị âm về 0."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "cols_to_exclude = ['Country/Region', 'Lat', 'Long']  # Thay bằng các cột bạn muốn giữ nguyên\n",
            "for name, df in daily_data.items():\n",
            "    # Lọc các cột cần thay đổi (không nằm trong cols_to_exclude)\n",
            "    cols_to_update = [col for col in df.columns if col not in cols_to_exclude]\n",
            "    \n",
            "    # Thay thế giá trị âm bằng 0 trong các cột được chọn\n",
            "    df[cols_to_update] = df[cols_to_update].map(lambda x: x if x >= 0 else 0)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Lưu file lại"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_dir = os.path.join(PROCESSED_DATA_PATH, 'daily_data')\n",
            "os.makedirs(output_dir, exist_ok=True)\n",
            "\n",
            "# Xuất từng DataFrame sang file CSV\n",
            "for data_type, df in daily_data.items():\n",
            "    # Tạo tên file\n",
            "    filename = f\"daily_{data_type}_cases.csv\"\n",
            "    filepath = os.path.join(output_dir, filename)\n",
            "    \n",
            "    # Xuất file CSV\n",
            "    df.to_csv(filepath, index=False)\n",
            "    print(f\"Đã xuất file {filename} thành công\")\n",
            "\n",
            "print(f\"\\nTất cả file đã được lưu tại: {output_dir}\")"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "base",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.16"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
